---
title: "Improved LD SuSiE using Thyroid data"
output:
  workflowr::wflow_html:
    toc: true
    toc_float: true
    code_folding: hide
---

In this experiment, we compare the SuSiE model for summary statistics under different types of the LD matrices. There are 5 types of covariance matrices as we mentioned earlier in the beginning of the page. Let's recall here once more

1. In-sample LD matrix: Gold standard

2. Out-sample LD matrix: LD matrix $\widehat{R}$ calculated from a out-of-sample data

3. Regularized: $\widehat{R}_{\lambda} = (1-\lambda) * \widehat{R} + \lambda * I$ with $\lambda = 0.1$

4. Truncated SVD: $\tilde{R}$ as presented in the paper

5. TSVD + Reg.: $\tilde{R}_{\lambda} = (1-\lambda) * \tilde{R} + \lambda * I$ with $\lambda = 0.1$

# 1. Preprocessing the data and ideas of this experiment

We used the Thyroid data which can be found in the data folder of the source code of this page. The size of the data is $n \times P$ where $n = 547$ is the sample size and $P=7470$ is the total number of SNPs.
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=10, dpi=150)
```
```{r load data, warning=FALSE}
library(susieR)
gtex <- readRDS("data/Thyroid_ENSG00000132855.rds")
```

In the following, we provide the coded-up function for the experiment where the outputs are SuSiE plots with their corresponding LD matrix. In terms of the procedure, we

+ removed the SNPs with $MAF < 0.01$,

+ randomly splitted the Thyroid data into two subsamples called in-sample ($n_1=474$) and out-of-sample ($n_2=100$) with $p = 200$. To maintain the correlation between Xs, we subsampled in a way that took consecutive SNPs.

+ standardized both sample matrices and calculated the out-sample LD matrix.

+ generated data from the in-sample X matrix where the chosen causal SNPs are in the set $\{1, 50, 100,150\}$ the corresponding non-zeros $\beta$s are $2,1,-2,3$. Specifically, 
$$y = X_{\text{in}}\boldsymbol{\beta} + \epsilon, \text{ where } \epsilon \sim \mathcal{N}_{474}(0,\sigma^2I_{474}), \boldsymbol{\beta} = \sum_{l=1}^4\boldsymbol{\beta}_l, \boldsymbol{\beta}_l = \gamma_l\beta_l,$$
where $\gamma_1, \gamma_2, \gamma_3, \gamma_4$ are vectors of all zero but only one value 1 in position $1, 50, 100, 150$, respectively, and ${\beta_1,\beta_2, \beta_3,\beta_4} = (2,1,-2,3)$. Standardized $y$.

+ Fitted univariate regression for $(y, X_{\text{in}})$ and calculated the Z-scores.
    

4. Given the known true causal SNPs, we run SuSiE assuming we know nothing about the data but only have the summary statistics.

Let's see how the different LD matrices affect the detection of causal SNPs.

```{r inital functions}
seed_vary = function(seed)
{
     set.seed(seed)
     print(paste("This is seed number", seed))
     ## good example: seed 3, 4, 8, 10, 11, 12
     ## bad example: seed 5
     # Remove SNPs with MAF < 0.01
     maf = apply(gtex, 2, function(x) sum(x)/2/length(x))
     X0 = gtex[, maf > 0.01]
     dim(X0)
     X = na.omit(X0)
     dim(X)
     snp_total = ncol(X0)
     n = nrow(X0)
     p = 200
     # Start from a random point on the genome
     indx_start = sample(1: (snp_total - p), 1)
     X = X0[, indx_start:(indx_start + p -1)]
     # View(cor(X)[1:10, 1:10])
     
     ## sub-sample into two
     out_sample = sample(1:n, 100)
     X_out = X[out_sample, ]
     X_in = X[setdiff(1:n, out_sample), ]
     sum(is.na(X_out))
     
     rm_p = c(which(diag(cov(X_in))==0), which(diag(cov(X_out))==0))
     length(rm_p)
     indx_p = setdiff(1:p, rm_p)
     X_in = X_in[, indx_p]
     X_out = X_out[, indx_p]
     
     ## Standardize both sample matrices
     X_in <- scale(X_in)
     X_out <- scale(X_out)
     
     ## out-sample LD matrix
     R_hat = cor(X_out)
     R = cor(X_in)
     # View(R_hat[1:10, 1:10])
     # View(R[1:10, 1:10])
     # View(cor(X)[1:10, 1:10])
     
     ## generate data from in-sample X matrix
     p = ncol(X_in)
     beta <- rep(0,p)
     n = nrow(X_in)
     beta[c(1, 50, 100, 150)] <- c(2, 1, -2, 3)
     # plot(beta, pch=16, ylab='effect size')
     y <- X_in %*% beta + rnorm(n)
     y = scale(y)
     
     ## compute summary statistics 
     sumstats <- univariate_regression(X_in, y)
     z_scores <- sumstats$betahat / sumstats$sebetahat
     # susie_plot(z_scores, y = "z", b=beta)
     min_cor = 0.01
     ## fit the susie-rss model with in-sample R
     fitted_rss1 <- susie_rss(bhat = sumstats$betahat, shat = sumstats$sebetahat, n = n, 
                              R = R, var_y = var(y), L = 10,
                              estimate_residual_variance = TRUE,
                              min_abs_corr=min_cor)
     # summary(fitted_rss1)$cs
     # p1 = susie_plot(fitted_rss1, y="PIP", b=beta)
     
     ## fit the model with out-sample R
     fitted_rss2 <- susie_rss(bhat = sumstats$betahat, shat = sumstats$sebetahat, n = n, 
                              R = R_hat, var_y = var(y), L = 10,
                              estimate_residual_variance = FALSE,
                              min_abs_corr=min_cor)
     # will have problem non-positive cov if estimate_residual_variance = TRUE
     # summary(fitted_rss2)$cs
     # p2 = susie_plot(fitted_rss2, y="PIP", b=beta) ## miss the true or does not run
     
     
     ## adjusted by identity matrix
     lambda = 0.1
     R_hat_lambd = (1-lambda) * R_hat + lambda * diag(p)
     fitted_rss3 <- susie_rss(bhat = sumstats$betahat, shat = sumstats$sebetahat, n = n, 
                              R = R_hat_lambd, var_y = var(y), L = 10,
                              estimate_residual_variance = F,
                              min_abs_corr=min_cor)
     # will have problem non-positive cov if estimate_residual_variance = TRUE
     # summary(fitted_rss3)$cs
     # susie_plot(fitted_rss3, y="PIP", b=beta) 
     
     ## using truncated SVD
     alph = 1
     XtY = t(X_in) %*% y
     ZZ = XtY %*% t(XtY) 
     R_hat_minus = R_hat - alph * ZZ / (n-1)^2
     eigen_R = eigen(R_hat_minus)
     eigen_R$values
     
     V <- eigen_R$vectors
     D_plus <- diag(pmax(eigen_R$values, 0))
     
     R_hat_plus <- V %*% D_plus %*% solve(V) + alph * ZZ / (n-1)^2
     
     fitted_rss4 <- susie_rss(bhat = sumstats$betahat, shat = sumstats$sebetahat, n = n, 
                              R = R_hat_plus, var_y = var(y), L = 10,
                              estimate_residual_variance = F,
                              min_abs_corr=min_cor)
     # summary(fitted_rss4)$cs
     # susie_plot(fitted_rss4, y="PIP", b=beta)
     
     ## combine strategy
     lambda = 0.1
     R_hat_plus_diag = (1-lambda) * R_hat_plus + lambda * diag(p)
     fitted_rss5 <- susie_rss(bhat = sumstats$betahat, shat = sumstats$sebetahat, n = n, 
                              R = R_hat_plus_diag, var_y = var(y), L = 10,
                              estimate_residual_variance = F,
                              min_abs_corr=min_cor)
     # summary(fitted_rss5)$cs
     # susie_plot(fitted_rss5, y="PIP", b=beta)
     
     par(mfrow = c(3, 2))
     susie_plot(z_scores, y = "z", b=beta)
     title('Z-score')
     susie_plot(fitted_rss1, y="PIP", b=beta)
     title('in-sample LD')
     susie_plot(fitted_rss2, y="PIP", b=beta)
     title('out-sample LD')
     susie_plot(fitted_rss3, y="PIP", b=beta)
     title('reg.+out-sample LD')
     susie_plot(fitted_rss4, y="PIP", b=beta)
     title('trunc.SVD out-sample LD')
     susie_plot(fitted_rss5, y="PIP", b=beta)
     title('reg+trunc.SVD out-sample LD')
     print(paste("Minimum eigenvalue is:",min(eigen_R$values,"corresponding to the seed", seed)))
}

```


# 2. Running the experiment with different seed

We vary the random seed to be from $1-20$. 

The following table records cases where the TSVD LD matrix provides a "better," equal, or worse PIP output compared to the out-sample LD matrix. The "better" here means improving power in detecting the causal SNPs and reducing FDR. 


```{r, message=FALSE, echo=FALSE}
library(knitr)
library(kableExtra)

# helper: clickable symbol with color
linked_symbol <- function(sym, col, seed) {
  sprintf("<a href='#seed%s-plot'><span style='color:%s; font-size:18px;'>%s</span></a>",
          seed, col, sym)
}

# Create table (3 rows x 20 seed columns + row labels)
df <- as.data.frame(matrix("", nrow = 3, ncol = 20))
colnames(df) <- paste0("seed ", 1:20)
df <- cbind(Result = c("better", "equal", "worse"), df)

# Fill with clickable symbols
df[1, 17+1] <- linked_symbol("⬤", "green", 17)  # better power, lower FDR
df[1, c(3,4,11,12,13)+1] <- sapply(c(3,4,11,12,13), function(s) linked_symbol("■", "green", s))
df[1, c(8,9,7,14,15,16,18)+1] <- sapply(c(8,9,7,14,15,16,18), function(s) linked_symbol("▲", "green", s))

df[2, c(2,6)+1] <- sapply(c(2,6), function(s) linked_symbol("✓", "orange", s))  # equal
df[3, c(1,5,19,20)+1] <- sapply(c(1,5,19,20), function(s) linked_symbol("x", "red", s))  # worse

# Render HTML table with borders
kable(df, "html", escape = FALSE, align = "c") %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("bordered", "condensed", "responsive", "hover"),
    position = "center",
    font_size = 14
  ) %>%
  row_spec(1, bold = TRUE, color = "green") %>%
  row_spec(2, bold = TRUE, color = "orange") %>%
  row_spec(3, bold = TRUE, color = "red") %>%
  column_spec(1, bold = TRUE, border_right = TRUE) %>%
  column_spec(2:21, border_left = TRUE, border_right = TRUE)
```
**Note**

+ <span style="color:green; font-size:20px;">■</span> for cases where the TSVD improved the power and reduce the FDR compare to out-sample LD.

+ <span style="color:green; font-size:20px;">●</span> for cases where the TSVD improved the power but increased the FDR compare to out-sample LD.

+ <span style="color:green; font-size:20px;">▲</span> for cases where the TSVD maintained the same power but reduced the FDR compare to out-sample LD.


```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
for (s in 1:20) {
  cat(sprintf("<a id='seed%s-plot'></a>\n\n", s))  # anchor
  seed_vary(s)  
}
```

